{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b1c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a8247d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10546, 2)\n",
      "(15819, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated tweets in train data:\n",
      "10.05 %\n"
     ]
    }
   ],
   "source": [
    "#Import data set\n",
    "df_test = pd.read_csv('data/test_with_no_labels.csv')\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)\n",
    "\n",
    "display(df_test.head())\n",
    "display(df_train.head())\n",
    "\n",
    "percent_duplicates = round((1-(df_train['message'].nunique()/len(df_train['message'])))*100,2)\n",
    "print('Duplicated tweets in train data:')\n",
    "print(percent_duplicates,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ed1def0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pro</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pro</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pro</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pro</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            message  tweetid\n",
       "0       Pro  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1       Pro  It's not like we lack evidence of anthropogeni...   126103\n",
       "2      News  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3       Pro  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4       Pro  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modifyDf():\n",
    "    df = df_train.copy()\n",
    "    sentiment = df['sentiment']\n",
    "    \n",
    "    word_sentiment = []    \n",
    "    for index in sentiment :\n",
    "        if index == 1 :\n",
    "            word_sentiment.append('Pro')\n",
    "        elif index == 0 :\n",
    "            word_sentiment.append('Neutral')\n",
    "        elif index == -1 :\n",
    "            word_sentiment.append('Anti')\n",
    "        else :\n",
    "            word_sentiment.append('News')\n",
    "            \n",
    "    df['sentiment'] = word_sentiment\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train_copy = modifyDf()\n",
    "df_train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dd7d7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>climate</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BeforeTheFlood</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>climatechange</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ImVotingBecause</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COP22</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hashtag  count\n",
       "19          climate    187\n",
       "24   BeforeTheFlood    129\n",
       "68    climatechange     94\n",
       "13  ImVotingBecause     62\n",
       "4             COP22     59"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hashtag_extract(tweet):\n",
    "    hashtags = []\n",
    "       \n",
    "    for i in tweet:\n",
    "        ht = re.findall(r\"#(\\w+)\", i)\n",
    "        hashtags.append(ht)\n",
    "        \n",
    "    hashtags = sum(hashtags, [])\n",
    "    frequency = nltk.FreqDist(hashtags)\n",
    "    \n",
    "    hashtag_df = pd.DataFrame({'hashtag': list(frequency.keys()),'count': list(frequency.values())})\n",
    "    hashtag_df = hashtag_df.nlargest(15, columns=\"count\")\n",
    "\n",
    "    return hashtag_df\n",
    "\n",
    "pro = hashtag_extract(df_train_copy['message'][df_train_copy['sentiment'] == 'Pro'])\n",
    "anti = hashtag_extract(df_train_copy['message'][df_train_copy['sentiment'] == 'Anti'])\n",
    "neutral = hashtag_extract(df_train_copy['message'][df_train_copy['sentiment'] == 'Neutral'])\n",
    "news = hashtag_extract(df_train_copy['message'][df_train_copy['sentiment'] == 'News'])\n",
    "\n",
    "pro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2413d88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pro</td>\n",
       "      <td>polyscimajor epa chief doesn t think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pro</td>\n",
       "      <td>it s not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pro</td>\n",
       "      <td>wired was a pivotal year in the war on climate...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pro</td>\n",
       "      <td>rt it s and a racist sexist climate change den...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            message  tweetid\n",
       "0       Pro  polyscimajor epa chief doesn t think carbon di...   625221\n",
       "1       Pro  it s not like we lack evidence of anthropogeni...   126103\n",
       "2      News  rt researchers say we have three years to act ...   698562\n",
       "3       Pro  wired was a pivotal year in the war on climate...   573736\n",
       "4       Pro  rt it s and a racist sexist climate change den...   466954"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CleanTweets(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('@[\\w]*','',tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)    \n",
    "    tweet = re.sub(r'\\d+', '', tweet)  \n",
    "    tweet = re.sub(r\"[,.;':@#?!\\&/$]+\\ *\", ' ', tweet)\n",
    "    tweet = re.sub(r\"U+FFFD \", ' ', tweet)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    tweet = tweet.lstrip(' ')                        \n",
    "\n",
    "    return tweet\n",
    "\n",
    "df_train_copy['message'] = df_train_copy['message'].apply(CleanTweets)\n",
    "\n",
    "df_train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08e454c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 24\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m#df['pos_tags'] = df['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m#df['lemmatized'] = df['pos_tags'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m#df['lemmatized'] = [' '.join(map(str, l)) for l in df['lemmatized']]  \u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 24\u001b[0m df_train_copy \u001b[38;5;241m=\u001b[39m \u001b[43mlemma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m df_train_copy\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m, in \u001b[0;36mlemma\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemma\u001b[39m(df):\n\u001b[0;32m     14\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlen()\n\u001b[1;32m---> 15\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[43mword_tokenize\u001b[49m)\n\u001b[0;32m     16\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos_tags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(nltk\u001b[38;5;241m.\u001b[39mtag\u001b[38;5;241m.\u001b[39mpos_tag)\n\u001b[0;32m     18\u001b[0m     wnl \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV    \n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemma(df):\n",
    "    df['length'] = df['message'].str.len()\n",
    "    df['tokenized'] = df['message'].apply(word_tokenize)\n",
    "    df['pos_tags'] = df['tokenized'].apply(nltk.tag.pos_tag)\n",
    "        \n",
    "    wnl = WordNetLemmatizer()\n",
    "    #df['pos_tags'] = df['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "    #df['lemmatized'] = df['pos_tags'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
    "    #df['lemmatized'] = [' '.join(map(str, l)) for l in df['lemmatized']]  \n",
    "    return df\n",
    "\n",
    "df_train_copy = lemma(df_train_copy)\n",
    "df_train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c7f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
