{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8edddfed",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-14T18:44:22.804671Z",
     "iopub.status.busy": "2023-05-14T18:44:22.804168Z",
     "iopub.status.idle": "2023-05-14T18:44:40.303283Z",
     "shell.execute_reply": "2023-05-14T18:44:40.302034Z"
    },
    "papermill": {
     "duration": 17.510385,
     "end_time": "2023-05-14T18:44:40.306292",
     "exception": false,
     "start_time": "2023-05-14T18:44:22.795907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\erasto.malema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\erasto.malema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\erasto.malema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\erasto.malema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Style\n",
    "import matplotlib.style as style \n",
    "sns.set(font_scale=1.5)\n",
    "style.use('seaborn-pastel')\n",
    "style.use('seaborn-poster')\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Downloads\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Preprocessing\n",
    "import en_core_web_sm\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords, wordnet  \n",
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "# Building classification models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf836eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:44:40.321622Z",
     "iopub.status.busy": "2023-05-14T18:44:40.320906Z",
     "iopub.status.idle": "2023-05-14T18:44:40.513107Z",
     "shell.execute_reply": "2023-05-14T18:44:40.511816Z"
    },
    "papermill": {
     "duration": 0.203159,
     "end_time": "2023-05-14T18:44:40.516085",
     "exception": false,
     "start_time": "2023-05-14T18:44:40.312926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import data set\n",
    "df_test = pd.read_csv('data/test_with_no_labels.csv')\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "#df_sample = pd.read_csv('data/sample_submission.csv')\n",
    "#df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43877539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:44:40.530641Z",
     "iopub.status.busy": "2023-05-14T18:44:40.530245Z",
     "iopub.status.idle": "2023-05-14T18:44:40.588389Z",
     "shell.execute_reply": "2023-05-14T18:44:40.586648Z"
    },
    "papermill": {
     "duration": 0.069307,
     "end_time": "2023-05-14T18:44:40.591730",
     "exception": false,
     "start_time": "2023-05-14T18:44:40.522423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10546, 2)\n",
      "(15819, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated tweets in train data:\n",
      "10.05 %\n"
     ]
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "print(df_train.shape)\n",
    "\n",
    "display(df_test.head())\n",
    "display(df_train.head())\n",
    "\n",
    "percent_duplicates = round((1-(df_train['message'].nunique()/len(df_train['message'])))*100,2)\n",
    "print('Duplicated tweets in train data:')\n",
    "print(percent_duplicates,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "190dd7d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:44:40.607725Z",
     "iopub.status.busy": "2023-05-14T18:44:40.607085Z",
     "iopub.status.idle": "2023-05-14T18:44:40.628554Z",
     "shell.execute_reply": "2023-05-14T18:44:40.627425Z"
    },
    "papermill": {
     "duration": 0.032699,
     "end_time": "2023-05-14T18:44:40.631359",
     "exception": false,
     "start_time": "2023-05-14T18:44:40.598660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pro</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pro</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pro</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pro</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            message  tweetid\n",
       "0       Pro  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1       Pro  It's not like we lack evidence of anthropogeni...   126103\n",
       "2      News  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3       Pro  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4       Pro  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modifyDf():\n",
    "    df = df_train.copy()\n",
    "    sentiment = df['sentiment']\n",
    "    \n",
    "    word_sentiment = []    \n",
    "    for index in sentiment :\n",
    "        if index == 1 :\n",
    "            word_sentiment.append('Pro')\n",
    "        elif index == 0 :\n",
    "            word_sentiment.append('Neutral')\n",
    "        elif index == -1 :\n",
    "            word_sentiment.append('Anti')\n",
    "        else :\n",
    "            word_sentiment.append('News')\n",
    "            \n",
    "    df['sentiment'] = word_sentiment\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train_copy = modifyDf()\n",
    "df_train_copy.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db60151c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:44:40.647381Z",
     "iopub.status.busy": "2023-05-14T18:44:40.646994Z",
     "iopub.status.idle": "2023-05-14T18:44:40.818584Z",
     "shell.execute_reply": "2023-05-14T18:44:40.817391Z"
    },
    "papermill": {
     "duration": 0.182854,
     "end_time": "2023-05-14T18:44:40.821372",
     "exception": false,
     "start_time": "2023-05-14T18:44:40.638518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>climate</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BeforeTheFlood</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>climatechange</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ImVotingBecause</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COP22</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hashtag  count\n",
       "19          climate    187\n",
       "24   BeforeTheFlood    129\n",
       "68    climatechange     94\n",
       "13  ImVotingBecause     62\n",
       "4             COP22     59"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hashtag_extract(tweet):\n",
    "    hashtags = []\n",
    "       \n",
    "    for i in tweet:\n",
    "        ht = re.findall(r\"#(\\w+)\", i)\n",
    "        hashtags.append(ht)\n",
    "        \n",
    "    hashtags = sum(hashtags, [])\n",
    "    frequency = nltk.FreqDist(hashtags)\n",
    "    \n",
    "    hashtag_df = pd.DataFrame({'hashtag': list(frequency.keys()),'count': list(frequency.values())})\n",
    "    hashtag_df = hashtag_df.nlargest(15, columns=\"count\")\n",
    "\n",
    "    return hashtag_df\n",
    "\n",
    "pro = hashtag_extract(df_train_copy['message'][df_train_copy['sentiment'] == 'Pro'])\n",
    "anti = hashtag_extract(df_train_copy['message'][df_train_copy['sentiment'] == 'Anti'])\n",
    "neutral = hashtag_extract(df_train_copy['message'][df_train_copy['sentiment'] == 'Neutral'])\n",
    "news = hashtag_extract(df_train_copy['message'][df_train_copy['sentiment'] == 'News'])\n",
    "\n",
    "pro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07f3170f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:44:40.837785Z",
     "iopub.status.busy": "2023-05-14T18:44:40.837350Z",
     "iopub.status.idle": "2023-05-14T18:44:41.292705Z",
     "shell.execute_reply": "2023-05-14T18:44:41.291159Z"
    },
    "papermill": {
     "duration": 0.466947,
     "end_time": "2023-05-14T18:44:41.295649",
     "exception": false,
     "start_time": "2023-05-14T18:44:40.828702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pro</td>\n",
       "      <td>polyscimajor epa chief doesn t think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pro</td>\n",
       "      <td>it s not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pro</td>\n",
       "      <td>wired was a pivotal year in the war on climate...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pro</td>\n",
       "      <td>rt it s and a racist sexist climate change den...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            message  tweetid\n",
       "0       Pro  polyscimajor epa chief doesn t think carbon di...   625221\n",
       "1       Pro  it s not like we lack evidence of anthropogeni...   126103\n",
       "2      News  rt researchers say we have three years to act ...   698562\n",
       "3       Pro  wired was a pivotal year in the war on climate...   573736\n",
       "4       Pro  rt it s and a racist sexist climate change den...   466954"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CleanTweets(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('@[\\w]*','',tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)    \n",
    "    tweet = re.sub(r'\\d+', '', tweet)  \n",
    "    tweet = re.sub(r\"[,.;':@#?!\\&/$]+\\ *\", ' ', tweet)\n",
    "    tweet = re.sub(r\"U+FFFD \", ' ', tweet)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    tweet = tweet.lstrip(' ')                        \n",
    "\n",
    "    return tweet\n",
    "\n",
    "df_train_copy['message'] = df_train_copy['message'].apply(CleanTweets)\n",
    "\n",
    "df_train_copy.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ffa9e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:44:41.313278Z",
     "iopub.status.busy": "2023-05-14T18:44:41.312876Z",
     "iopub.status.idle": "2023-05-14T18:45:06.821549Z",
     "shell.execute_reply": "2023-05-14T18:45:06.820409Z"
    },
    "papermill": {
     "duration": 25.520657,
     "end_time": "2023-05-14T18:45:06.823978",
     "exception": false,
     "start_time": "2023-05-14T18:44:41.303321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>length</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pro</td>\n",
       "      <td>polyscimajor epa chief doesn t think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>102</td>\n",
       "      <td>[polyscimajor, epa, chief, doesn, t, think, ca...</td>\n",
       "      <td>[(polyscimajor, a), (epa, n), (chief, n), (doe...</td>\n",
       "      <td>polyscimajor epa chief doesn t think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pro</td>\n",
       "      <td>it s not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>62</td>\n",
       "      <td>[it, s, not, like, we, lack, evidence, of, ant...</td>\n",
       "      <td>[(it, n), (s, v), (not, r), (like, n), (we, n)...</td>\n",
       "      <td>it s not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>698562</td>\n",
       "      <td>86</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[(rt, n), (researchers, n), (say, v), (we, n),...</td>\n",
       "      <td>rt researcher say we have three year to act on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pro</td>\n",
       "      <td>wired was a pivotal year in the war on climate...</td>\n",
       "      <td>573736</td>\n",
       "      <td>54</td>\n",
       "      <td>[wired, was, a, pivotal, year, in, the, war, o...</td>\n",
       "      <td>[(wired, v), (was, v), (a, n), (pivotal, a), (...</td>\n",
       "      <td>wire be a pivotal year in the war on climate c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pro</td>\n",
       "      <td>rt it s and a racist sexist climate change den...</td>\n",
       "      <td>466954</td>\n",
       "      <td>81</td>\n",
       "      <td>[rt, it, s, and, a, racist, sexist, climate, c...</td>\n",
       "      <td>[(rt, v), (it, n), (s, n), (and, n), (a, n), (...</td>\n",
       "      <td>rt it s and a racist sexist climate change den...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            message  tweetid  \\\n",
       "0       Pro  polyscimajor epa chief doesn t think carbon di...   625221   \n",
       "1       Pro  it s not like we lack evidence of anthropogeni...   126103   \n",
       "2      News  rt researchers say we have three years to act ...   698562   \n",
       "3       Pro  wired was a pivotal year in the war on climate...   573736   \n",
       "4       Pro  rt it s and a racist sexist climate change den...   466954   \n",
       "\n",
       "   length                                          tokenized  \\\n",
       "0     102  [polyscimajor, epa, chief, doesn, t, think, ca...   \n",
       "1      62  [it, s, not, like, we, lack, evidence, of, ant...   \n",
       "2      86  [rt, researchers, say, we, have, three, years,...   \n",
       "3      54  [wired, was, a, pivotal, year, in, the, war, o...   \n",
       "4      81  [rt, it, s, and, a, racist, sexist, climate, c...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [(polyscimajor, a), (epa, n), (chief, n), (doe...   \n",
       "1  [(it, n), (s, v), (not, r), (like, n), (we, n)...   \n",
       "2  [(rt, n), (researchers, n), (say, v), (we, n),...   \n",
       "3  [(wired, v), (was, v), (a, n), (pivotal, a), (...   \n",
       "4  [(rt, v), (it, n), (s, n), (and, n), (a, n), (...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  polyscimajor epa chief doesn t think carbon di...  \n",
       "1  it s not like we lack evidence of anthropogeni...  \n",
       "2  rt researcher say we have three year to act on...  \n",
       "3  wire be a pivotal year in the war on climate c...  \n",
       "4  rt it s and a racist sexist climate change den...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV    \n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemma(df):\n",
    "    df['length'] = df['message'].str.len()\n",
    "    df['tokenized'] = df['message'].apply(word_tokenize)\n",
    "    df['pos_tags'] = df['tokenized'].apply(nltk.tag.pos_tag)\n",
    "        \n",
    "    wnl = WordNetLemmatizer()\n",
    "    df['pos_tags'] = df['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "    df['lemmatized'] = df['pos_tags'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
    "    df['lemmatized'] = [' '.join(map(str, l)) for l in df['lemmatized']]  \n",
    "    return df\n",
    "\n",
    "df_train_copy = lemma(df_train_copy)\n",
    "df_train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "affdce57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:45:06.841331Z",
     "iopub.status.busy": "2023-05-14T18:45:06.840923Z",
     "iopub.status.idle": "2023-05-14T18:45:06.852769Z",
     "shell.execute_reply": "2023-05-14T18:45:06.851541Z"
    },
    "papermill": {
     "duration": 0.0238,
     "end_time": "2023-05-14T18:45:06.855574",
     "exception": false,
     "start_time": "2023-05-14T18:45:06.831774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Building classification models\n",
    "#Split the dataset into train & validation (25%) for model training\n",
    "\n",
    "# Seperate features and tagret variables\n",
    "X = df_train['message']\n",
    "y = df_train['sentiment']\n",
    "\n",
    "# Split the train data to create validation dataset\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c50a03d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:45:06.873881Z",
     "iopub.status.busy": "2023-05-14T18:45:06.873470Z",
     "iopub.status.idle": "2023-05-14T18:45:08.146675Z",
     "shell.execute_reply": "2023-05-14T18:45:08.145556Z"
    },
    "papermill": {
     "duration": 1.285738,
     "end_time": "2023-05-14T18:45:08.149905",
     "exception": false,
     "start_time": "2023-05-14T18:45:06.864167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       336\n",
      "           0       0.00      0.00      0.00       547\n",
      "           1       0.55      1.00      0.71      2178\n",
      "           2       0.00      0.00      0.00       894\n",
      "\n",
      "    accuracy                           0.55      3955\n",
      "   macro avg       0.14      0.25      0.18      3955\n",
      "weighted avg       0.30      0.55      0.39      3955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erasto.malema\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\erasto.malema\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\erasto.malema\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', RandomForestClassifier(max_depth=5, n_estimators=100))])\n",
    "\n",
    "# Train Random forest \n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_valid)\n",
    "\n",
    "# Generate a classification Report for the random forest model\n",
    "print(metrics.classification_report(y_valid, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8353bfcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:45:08.168461Z",
     "iopub.status.busy": "2023-05-14T18:45:08.167597Z",
     "iopub.status.idle": "2023-05-14T18:45:08.774615Z",
     "shell.execute_reply": "2023-05-14T18:45:08.773410Z"
    },
    "papermill": {
     "duration": 0.619318,
     "end_time": "2023-05-14T18:45:08.777403",
     "exception": false,
     "start_time": "2023-05-14T18:45:08.158085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       336\n",
      "           0       1.00      0.05      0.09       547\n",
      "           1       0.60      0.99      0.75      2178\n",
      "           2       0.94      0.33      0.48       894\n",
      "\n",
      "    accuracy                           0.63      3955\n",
      "   macro avg       0.63      0.34      0.33      3955\n",
      "weighted avg       0.68      0.63      0.53      3955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erasto.malema\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\erasto.malema\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\erasto.malema\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Naïve Bayes:\n",
    "nb = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])\n",
    "\n",
    "# Train Niave bayes\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_valid)\n",
    "\n",
    "# Generate a classification Report for the Naive Bayes model\n",
    "print(metrics.classification_report(y_valid, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29453f07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:45:08.796440Z",
     "iopub.status.busy": "2023-05-14T18:45:08.795996Z",
     "iopub.status.idle": "2023-05-14T18:45:19.101309Z",
     "shell.execute_reply": "2023-05-14T18:45:19.099986Z"
    },
    "papermill": {
     "duration": 10.318588,
     "end_time": "2023-05-14T18:45:19.104515",
     "exception": false,
     "start_time": "2023-05-14T18:45:08.785927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.40      0.47       336\n",
      "           0       0.48      0.39      0.43       547\n",
      "           1       0.74      0.81      0.77      2178\n",
      "           2       0.68      0.66      0.67       894\n",
      "\n",
      "    accuracy                           0.69      3955\n",
      "   macro avg       0.62      0.57      0.59      3955\n",
      "weighted avg       0.67      0.69      0.68      3955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-NN Classifier\n",
    "knn = Pipeline([('tfidf', TfidfVectorizer()), ('clf', KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2))])\n",
    "\n",
    "# Train K - nearest neighbors\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3315365f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:45:19.123954Z",
     "iopub.status.busy": "2023-05-14T18:45:19.123562Z",
     "iopub.status.idle": "2023-05-14T18:45:26.122913Z",
     "shell.execute_reply": "2023-05-14T18:45:26.121711Z"
    },
    "papermill": {
     "duration": 7.011555,
     "end_time": "2023-05-14T18:45:26.125338",
     "exception": false,
     "start_time": "2023-05-14T18:45:19.113783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.66      0.60       336\n",
      "           0       0.50      0.56      0.53       547\n",
      "           1       0.86      0.69      0.77      2178\n",
      "           2       0.65      0.88      0.75       894\n",
      "\n",
      "    accuracy                           0.71      3955\n",
      "   macro avg       0.64      0.70      0.66      3955\n",
      "weighted avg       0.74      0.71      0.72      3955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = Pipeline([('tfidf',TfidfVectorizer()), ('clf',LogisticRegression(C=1, class_weight='balanced', max_iter=1000))])\n",
    "\n",
    "# Train Linear regression\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07201523",
   "metadata": {
    "papermill": {
     "duration": 0.008052,
     "end_time": "2023-05-14T18:45:26.141860",
     "exception": false,
     "start_time": "2023-05-14T18:45:26.133808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc4a729d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:45:26.160516Z",
     "iopub.status.busy": "2023-05-14T18:45:26.160141Z",
     "iopub.status.idle": "2023-05-14T18:45:27.086169Z",
     "shell.execute_reply": "2023-05-14T18:45:27.084874Z"
    },
    "papermill": {
     "duration": 0.938481,
     "end_time": "2023-05-14T18:45:27.088722",
     "exception": false,
     "start_time": "2023-05-14T18:45:26.150241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.57      0.60       336\n",
      "           0       0.57      0.49      0.53       547\n",
      "           1       0.82      0.80      0.81      2178\n",
      "           2       0.71      0.84      0.77       894\n",
      "\n",
      "    accuracy                           0.75      3955\n",
      "   macro avg       0.68      0.68      0.68      3955\n",
      "weighted avg       0.74      0.75      0.74      3955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC:\n",
    "lsvc = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC(class_weight='balanced'))])\n",
    "\n",
    "# Train Linear SVC\n",
    "lsvc.fit(X_train, y_train)\n",
    "y_pred_lsvc = lsvc.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred_lsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e97f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:45:27.107958Z",
     "iopub.status.busy": "2023-05-14T18:45:27.107549Z",
     "iopub.status.idle": "2023-05-14T18:45:28.438513Z",
     "shell.execute_reply": "2023-05-14T18:45:28.436928Z"
    },
    "papermill": {
     "duration": 1.344519,
     "end_time": "2023-05-14T18:45:28.441815",
     "exception": false,
     "start_time": "2023-05-14T18:45:27.097296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score improved by 2.0 %\n"
     ]
    }
   ],
   "source": [
    "# Retrain linear SVC using optimal hyperparameters:\n",
    "lsvc_op = Pipeline([('tfidf', TfidfVectorizer(max_df=0.8,\n",
    "                                                    min_df=2,\n",
    "                                                    ngram_range=(1,2))),\n",
    "                  ('clf', LinearSVC(C=0.3,\n",
    "                                    class_weight='balanced',\n",
    "                                    max_iter=3000))])\n",
    "\n",
    "# Fit and predict\n",
    "lsvc_op.fit(X_train, y_train)\n",
    "y_pred = lsvc_op.predict(X_valid)\n",
    "\n",
    "print('F1 score improved by',\n",
    "      round(100*((metrics.accuracy_score(y_pred, y_valid) - metrics.accuracy_score(y_pred_lsvc, y_valid)) /metrics.accuracy_score(y_pred_lsvc, y_valid)),0), \n",
    "      '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c0f90f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T18:45:28.462223Z",
     "iopub.status.busy": "2023-05-14T18:45:28.461827Z",
     "iopub.status.idle": "2023-05-14T18:45:29.080865Z",
     "shell.execute_reply": "2023-05-14T18:45:29.079693Z"
    },
    "papermill": {
     "duration": 0.631634,
     "end_time": "2023-05-14T18:45:29.083576",
     "exception": false,
     "start_time": "2023-05-14T18:45:28.451942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>872928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>895714</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>875167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>78329</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>867455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>470892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10546 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweetid  sentiment\n",
       "0       169760          1\n",
       "1        35326          1\n",
       "2       224985          1\n",
       "3       476263          1\n",
       "4       872928          0\n",
       "...        ...        ...\n",
       "10541   895714         -1\n",
       "10542   875167          1\n",
       "10543    78329          2\n",
       "10544   867455          0\n",
       "10545   470892          1\n",
       "\n",
       "[10546 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = lsvc_op.predict(df_test['message'])\n",
    "output = pd.DataFrame({'tweetid': df_test.tweetid, 'sentiment': y_test})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 82.788079,
   "end_time": "2023-05-14T18:45:32.619725",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-14T18:44:09.831646",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
